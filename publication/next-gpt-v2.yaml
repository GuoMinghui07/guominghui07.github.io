title: NExT-GPT v2: A Unified Any-to-Any Multimodal LLM
venue: Preprint Version
year: 2026
authors:
  - Minghui Guo, Shengqiong Wu, Wynne Hsu, Lee Mong Li, Shuicheng Yan, Philip Torr, Tat Seng Chua, Hao Fei*.
description: A unified any-to-any multimodal large language model for generalized cross-modal understanding and generation.
